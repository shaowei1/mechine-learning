from math import logimport operator"""得到熵之后，我们可以按照获取最大信息增益的方法划分数据集，(划分数据集，度量增益)另一个度量集合无序成都的方法是基尼不纯度(Gini impurity): 从一个数据集中随机选取指向，度量其被错误分类到其他分组你的概率, """def calcShannonEnt(dataSet):    """    计算给定数据集的香农熵    :param dataSet:    :return:    """    numEntries = len(dataSet)    labelCounts = {}    # 为所有可能分类创建字典    for featVec in dataSet:        currentLabel = featVec[-1]        if currentLabel not in labelCounts.keys():            labelCounts[currentLabel] = 0        labelCounts[currentLabel] += 1    shannonEnt = 0.0    for key in labelCounts:        prob = float(labelCounts[key]) / numEntries        # 以2为低数来求对数        shannonEnt -= prob * log(prob, 2)    return shannonEntdef createDataSet():    dataSet = [[1, 1, 'yes'],               [1, 1, 'yes'],               [1, 0, 'no'],               [0, 1, 'no'],               [0, 1, 'no']]    labels = ['no surfacing', 'flippers']    return dataSet, labelsdef splitDataSet(dataSet, axis, value):    """    划分数据集    :param dataSet: 待划分的数据集    :param axis: 划分数据集的特征    :param value: 需要返回的特征值    :return:    python 语言在函数中传递的是列表的引用，在函数内部对列表对象的修改，将会影响列表的整个生命周期，    为了消除这个不良影响，我们需要在函数的开始声明一个新的列表对象    """    retDataSet = []    for featVec in dataSet:        if featVec[axis] == value:            # 抽取            # list[a:b]　左开右闭            reducedFeatVec = featVec[:axis]            reducedFeatVec.extend(featVec[axis + 1:])            retDataSet.append(reducedFeatVec)    return retDataSetdef chooseBestFeatureToSplit(dataSet):    """    选取特征，划分数据集    选择最好的数据集划分方式    :param dataSet: 数据必须是有列表元素组成的列表，所有列表元素具有相同的数据长度，                    数据的最后一列或者每个实例的最后一个元素是当前实例的列表标签    :return: 最好的划分数据集的特征    """    numFeatures = len(dataSet[0]) - 1  # 2个特征    # 整个数据集的原始香农熵，我们保存最初的无序度量值，用于与划分玩之后的数据集计算的熵值进行比较    baseEntropy = calcShannonEnt(dataSet)    bestInfoGain = 0.0    bestFeature = -1    for i in range(numFeatures):        # 创建唯一的分类标签列表        featList = [example[i] for example in dataSet]        uniqueVals = set(featList)        newEntropy = 0.0        # 计算每种划分方式的信息熵        for value in uniqueVals:            subDataSet = splitDataSet(dataSet, i, value)            prob = len(subDataSet) / float(len(dataSet))            newEntropy += prob * calcShannonEnt(subDataSet)        """        信息增益是熵的减少或者是数据无序度的减少，大家肯定对于将熵用于度量数据无序度的减少更容易理解        """        infoGain = baseEntropy - newEntropy        if (infoGain > bestInfoGain):            bestInfoGain = infoGain            bestFeature = i    return bestFeaturedef majorityCnt(classList):    """    :param classList: 分类名称的列表    :return: 出现次数最多的分类名称    """    classCount = {}  # 存储每个标签出现的频率    for vote in classList:        if vote not in classCount.keys():            classCount[vote] = 0        classCount[vote] += 1    sortedClassCount = sorted(classCount.items(), key=operator.itemgetter(1), reverse=True)    return sortedClassCount[0][0]def createTree(dataSet, labels):    """    创建树    :param dataSet: 数据集    :param labels: 标签列表    :return:    """    classList = [example[-1] for example in dataSet]    if classList.count(classList[0]) == len(classList):  # 当所有的类标签相同，这返回该类标签, 前部是yes, 或者全部是no        return classList[0]    if len(dataSet[0]) == 1:  # 用完了所有特征，仍然不能将数据集划分成仅包含唯一列别的分组        return majorityCnt(classList)  # 挑选次数最多的类别作为返回值    #    bestFeat = chooseBestFeatureToSplit(dataSet)  # 当前数据集选取的最好特征    bestFeatLabel = labels[bestFeat]    myTree = {bestFeatLabel: {}}    del (labels[bestFeat])    featValues = [example[bestFeat] for example in dataSet]  # 得到列表包含的所有属性值    uniqueVals = set(featValues)    for value in uniqueVals:        subLabels = labels[:]  # 保证每次调用函数createTree()时不改变原始列表的内容        myTree[bestFeatLabel][value] = createTree(splitDataSet(dataSet, bestFeat, value), subLabels)    return myTreeif __name__ == '__main__':    myDat, labels = createDataSet()    myTree = createTree(myDat, labels)    print(myTree)    # res = chooseBestFeatureToSplit(myDat)    # print(res)    # pass    #    # # myDat[0][-1] = 'maybe'    # print(myDat, labels)    # res = calcShannonEnt(myDat)    # print(res)    # # 根据第一列的值进行判断    # a = splitDataSet(myDat, 0, 1)    # b = splitDataSet(myDat, 0, 0)    # print(a)    # print(b)